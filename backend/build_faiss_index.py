import os
import json
import pickle
import random
import pandas as pd
import requests
from PIL import Image
from io import BytesIO
from tqdm import tqdm
import faiss
import numpy as np
import torch
from transformers import CLIPProcessor, CLIPModel
import time
from huggingface_hub import HfFolder

# Constants
PARQUET_PATH = "data/diffusiondb_full/metadata.parquet"
SAVE_DIR = "data/embedded_subset"
NUM_IMAGES = 10000
CLIP_DIM = 512
CACHE_DIR = "E:\\ml_cache\\huggingface"
os.makedirs(SAVE_DIR, exist_ok=True)
os.makedirs(CACHE_DIR, exist_ok=True)

os.environ["HF_HOME"] = CACHE_DIR
os.environ["TRANSFORMERS_CACHE"] = os.path.join(CACHE_DIR, "transformers")
os.environ["HF_DATASETS_CACHE"] = os.path.join(CACHE_DIR, "datasets")

# Get token using huggingface_hub's built-in method
token = HfFolder.get_token()
if not token:
    print("\n‚ùå No valid token found!")
    print("\nPlease run this command first:")
    print('huggingface-cli login --token YOUR_TOKEN')
    raise ValueError("Please log in to Hugging Face first")

print(f"\nFound token starting with: {token[:4]}...")

# Set up headers
HEADERS = {
    "Authorization": f"Bearer {token}",
    "user-agent": "huggingface_hub/0.31.2",
}

# Test the token with a simple API call
print("\nüîÑ Testing HF token...")
test_url = "https://huggingface.co/api/whoami"
try:
    response = requests.get(test_url, headers=HEADERS)
    if response.status_code == 200:
        print("‚úÖ Token is valid!")
        print(f"Logged in as: {response.json().get('name')}")
    else:
        print(f"‚ùå Token test failed with status code: {response.status_code}")
        print(f"Response: {response.text}")
        print("\nPlease run this command to log in again:")
        print('huggingface-cli login --token YOUR_TOKEN')
        raise ValueError("Invalid token")
except Exception as e:
    print(f"‚ùå Token test failed with error: {str(e)}")
    raise

# Load CLIP
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32", cache_dir=CACHE_DIR).to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32", cache_dir=CACHE_DIR)

def download_image(part_id, image_name):
    url = f"https://huggingface.co/datasets/poloclub/diffusiondb/resolve/main/images/part-{part_id:06d}/{image_name}"

    for attempt in range(5):
        try:
            head = requests.head(url, headers=HEADERS)
            if head.status_code == 404:
                return None
            if head.status_code == 429:
                print("‚è≥ Rate limited. Waiting...")
                time.sleep(5 * (attempt + 1))
                continue

            response = requests.get(url, headers=HEADERS, timeout=20)
            response.raise_for_status()
            return Image.open(BytesIO(response.content)).convert("RGB")
        except Exception as e:
            print(f"‚ùå Failed to download {image_name} (attempt {attempt + 1}): {e}")
            time.sleep(2 * (attempt + 1))

    return None

def get_image_embedding(image):
    inputs = processor(images=image, return_tensors="pt").to(device)
    with torch.no_grad():
        features = model.get_image_features(**inputs)
    features = features / features.norm(dim=-1, keepdim=True)
    return features.cpu().numpy()

def main():
    print("üìñ Loading metadata...")
    try:
        # Read the parquet file
        df = pd.read_parquet(PARQUET_PATH)
        print(f"\nüìä Total rows: {len(df)}")
        
        # Take a random sample
        print("\nüé≤ Taking random sample...")
        sampled = df.sample(n=min(NUM_IMAGES * 2, len(df)), random_state=42)
        print(f"üìä Sampled {len(sampled)} rows")
        
        index = faiss.IndexFlatL2(CLIP_DIM)
        metadata = []

        count = 0
        for _, row in tqdm(sampled.iterrows(), total=len(sampled), desc="üîÅ Downloading & Embedding"):
            if count >= NUM_IMAGES:
                break

            image = download_image(row["part_id"], row["image_name"])
            if not image:
                continue

            try:
                embedding = get_image_embedding(image)
                index.add(embedding)

                # Extract metadata dynamically from the row
                meta = {
                    "prompt": row.get("prompt", ""),
                    "seed": int(row["seed"]) if pd.notna(row.get("seed")) else None,
                    "cfg": float(row.get("cfg", 7.5)),
                    "steps": int(row.get("step", 30)),
                    "sampler": row.get("sampler", "unknown"),
                }
                
                for key in row.index:
                    if key not in ["prompt", "seed", "cfg", "step", "sampler", "part_id", "image_name"]:
                        if pd.notna(row[key]):
                            meta[key] = row[key]

                metadata.append(meta)
                count += 1

            except Exception as e:
                print(f"‚ö†Ô∏è Failed to embed image {row['image_name']}: {e}")

        print(f"\n‚úÖ Indexing complete: {index.ntotal} vectors")

        # Save index + metadata
        faiss.write_index(index, os.path.join(SAVE_DIR, "prompt_index.faiss"))
        with open(os.path.join(SAVE_DIR, "prompt_metadata.pkl"), "wb") as f:
            pickle.dump(metadata, f)

        print("üì¶ Saved FAISS index + metadata")
        
    except Exception as e:
        print(f"\n‚ùå Error reading parquet file: {e}")
        print("\nüîç Debug info:")
        print(f"File exists: {os.path.exists(PARQUET_PATH)}")
        print(f"File size: {os.path.getsize(PARQUET_PATH) / (1024*1024):.2f} MB")
        raise

if __name__ == "__main__":
    main()
